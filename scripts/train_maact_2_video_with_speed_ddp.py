import argparse
import glob
import os
import pickle
import sys
import time
from datetime import timedelta

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.distributed as dist  # [DDP]
from torch.nn.parallel import DistributedDataParallel as DDP  # [DDP]
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler  # [DDP]

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from dataset.efficient_dataset import EfficientEpisodicDataset
from policy.maact.common.configs.configuration_act import SpeedACTConfig
from policy.maact.common.model.speed_act_with_speed_decoder_query import SpeedACT
from dataset.utils_norm import get_norm_stats
from scripts.utils_train import setup_logger, get_run_dirs, save_train_loss_plot, kl_divergence
from dataset.efficient_ma_dynamic_video_dataset import VideoBasedEfficientMADataset


# [DDP] å·¥å…·å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹
def is_main_process():
    return not dist.is_initialized() or dist.get_rank() == 0


def main():
    parser = argparse.ArgumentParser(description="ACT DDP Training Script")
    parser.add_argument('--video', action='store_true', help='Use video dataset (load from .mp4)')
    parser.add_argument('--fisheye', action='store_true', help='Use video dataset (load from .mp4)')
    parser.add_argument('--resume', type=str, default=None, help='Path to checkpoint to resume from')
    parser.add_argument('--start_epoch', type=int, default=0, help='Epoch to start from')
    args = parser.parse_args()

    # [DDP] 1. åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    # torchrun ä¼šè‡ªåŠ¨è®¾ç½® LOCAL_RANK ç­‰ç¯å¢ƒå˜é‡
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    torch.cuda.set_device(local_rank)
    dist.init_process_group(backend='nccl', init_method='env://')
    device = torch.device(f"cuda:{local_rank}")

    global_rank = dist.get_rank()
    world_size = dist.get_world_size()
    TARGET_SIZE = (640, 480)
    if args.fisheye:
        TARGET_SIZE = (480, 480)

    # è·¯å¾„é…ç½®
    if args.video:
        DATA_DIR = r'/root/Users/zhanguozhi/lumos/data/012_rot/episode'
    else:
        DATA_DIR = r'F:\projects\lumos\data\20260109'  # æ³¨æ„ï¼šLinuxä¸‹è·¯å¾„æ ¼å¼ä¸åŒï¼Œç¡®ä¿å¤šå¡ç¯å¢ƒæ˜¯Linux

    # [DDP] ä»…åœ¨ä¸»è¿›ç¨‹è®¾ç½® Logger å’Œåˆ›å»ºç›®å½•
    logger = None
    CKPT_DIR = None
    RUN_DIR = None

    if is_main_process():
        RUN_DIR, CKPT_DIR, RUN_NAME = get_run_dirs("./logs_maact")
        logger = setup_logger(RUN_DIR, name="MA_ACT")
        STATS_PATH = os.path.join(CKPT_DIR, 'dataset_stats.pkl')

        mode_str = "VIDEO-Based" if args.video else "HDF5-RAM-Based"
        logger.info(f"ğŸš€ MA-ACT DDP Training Started! Mode: [{mode_str}] | Run ID: {RUN_NAME}")
        logger.info(f"Using {world_size} GPUs.")
    else:
        # å…¶ä»–è¿›ç¨‹åªéœ€çŸ¥é“ STATS_PATH åœ¨å“ªé‡Œï¼ˆé€šå¸¸éœ€è¦æŒ‡å‘ä¸€ä¸ªå…¬å…±è·¯å¾„ï¼Œæˆ–è€…ç”± Rank 0 å¹¿æ’­ï¼‰
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œå‡è®¾ stats è·¯å¾„é€»è¾‘éœ€è¦åŒæ­¥ã€‚
        # æ›´å¥½çš„åšæ³•æ˜¯ï¼šRank 0 è®¡ç®—å®Œ stats åï¼Œå¹¿æ’­ç»™å…¶ä»–è¿›ç¨‹ï¼Œæˆ–è€…å­˜åˆ°ä¸€ä¸ªå›ºå®šä½ç½®ã€‚
        # ä¸‹é¢é€»è¾‘ä¸­æˆ‘ä»¬ä¼šç”¨ barrier è§£å†³ stats è®¡ç®—å†²çªã€‚
        # æ³¨æ„ï¼šè¿™é‡Œ CKPT_DIR å¯¹é Rank0 æ˜¯ Noneï¼Œåç»­è¦å°å¿ƒä½¿ç”¨
        pass

    # è¶…å‚æ•°é…ç½®
    NUM_EPOCHS = 2000
    BATCH_SIZE = 64
    LR = 1e-4
    LR_BACKBONE = 1e-5
    CHUNK_SIZE = 50
    KL_WEIGHT = 10.0
    CLS_WEIGHT = 0.2

    CAMERA_NAMES = ['cam_high']
    MAIN_CAMERA_NAME = 'cam_high'
    N_OBS_STEPS = 1
    NUM_SPEED_CATEGORIES = 3

    num_workers = 7

    dataset_path_list = glob.glob(os.path.join(DATA_DIR, '*.hdf5'))

    stats = None
    if is_main_process():
        # Rank 0 è´Ÿè´£è®¡ç®—æˆ–åŠ è½½
        # æ³¨æ„ï¼šä¸ºäº†è®©å…¶ä»–è¿›ç¨‹ä¹Ÿèƒ½è¯»å–ï¼ŒSTATS_PATH æœ€å¥½æ˜¯ä¸€ä¸ªå…¬å…±å¯è¯»è·¯å¾„ï¼Œè€Œä¸æ˜¯åŠ¨æ€ç”Ÿæˆçš„ CKPT_DIR
        # è¿™é‡Œæˆ‘ä»¬ä¸´æ—¶ç”Ÿæˆï¼Œç„¶åé€šè¿‡ torch.save/load æˆ–è€…å¹¿æ’­åŒæ­¥
        logger.info(f"Rank 0: Preparing stats from {DATA_DIR}...")
        stats = get_norm_stats(DATA_DIR)
        # å¦‚æœéœ€è¦ä¿å­˜åˆ°ç£ç›˜ä¾›åç»­ä½¿ç”¨
        with open(STATS_PATH, 'wb') as f:
            pickle.dump(stats, f)

    # [DDP] åŒæ­¥ Stats æ•°æ®
    # å°† stats å¯¹è±¡å¹¿æ’­ç»™æ‰€æœ‰è¿›ç¨‹
    stats_list = [stats]
    dist.broadcast_object_list(stats_list, src=0)
    stats = stats_list[0]

    # ç­‰å¾…åŒæ­¥å®Œæˆ
    dist.barrier()

    STATE_DIM = stats['qpos_mean'].shape[0]
    ACTION_DIM = stats['action_mean'].shape[0]

    # [DDP] æ•°æ®é›†åˆå§‹åŒ– (æ‰€æœ‰è¿›ç¨‹éƒ½éœ€è¦åˆå§‹åŒ–æ•°æ®é›†)
    if args.video:
        if is_main_process(): logger.info(f"Initializing Video MA-Dataset...")
        train_dataset = VideoBasedEfficientMADataset(
            dataset_path_list, stats,
            camera_names=CAMERA_NAMES,
            chunk_size=CHUNK_SIZE,
            n_obs_steps=N_OBS_STEPS,
            target_size=TARGET_SIZE
        )
    else:
        if is_main_process(): logger.info(f"Initializing HDF5 MA-Dataset...")
        train_dataset = EfficientEpisodicDataset(
            dataset_path_list, stats,
            camera_names=CAMERA_NAMES,
            chunk_size=CHUNK_SIZE,
            n_obs_steps=N_OBS_STEPS
        )

    # [DDP] 2. ä½¿ç”¨ DistributedSampler
    train_sampler = DistributedSampler(train_dataset, shuffle=True)

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,  # [DDP] å¿…é¡»è®¾ä¸º Falseï¼Œshuffle ç”± sampler æ§åˆ¶
        sampler=train_sampler,  # [DDP] ä¼ å…¥ sampler
        pin_memory=True,
        num_workers=num_workers,
        prefetch_factor=2
    )

    # æ¨¡å‹åˆå§‹åŒ–
    config = SpeedACTConfig(
        dim_model=512,
        n_heads=8,
        dim_feedforward=3200,
        n_encoder_layers=4,
        n_decoder_layers=1,
        chunk_size=CHUNK_SIZE,
        n_obs_steps=N_OBS_STEPS,
        image_features={cam: (3, TARGET_SIZE[1], TARGET_SIZE[0]) for cam in CAMERA_NAMES},
        main_camera=MAIN_CAMERA_NAME,
        robot_state_feature=(STATE_DIM,),
        action_feature=(ACTION_DIM,),
        use_optical_flow=False,
        num_speed_categories=NUM_SPEED_CATEGORIES,
        feedforward_activation="relu",
        pre_norm=False,
        global_flow_size=128,
        optical_flow_map_height=256,
        optical_flow_map_width=320,
    )

    policy = SpeedACT(config)
    policy.to(device)  # å…ˆç§»åŠ¨åˆ°å¯¹åº” GPU

    # [DDP] 3. SyncBatchNorm (å¯é€‰ï¼Œå»ºè®®å¼€å¯) å’Œ DDP å°è£…
    policy = torch.nn.SyncBatchNorm.convert_sync_batchnorm(policy)
    policy = DDP(policy, device_ids=[local_rank], output_device=local_rank)

    # ä¼˜åŒ–å™¨éœ€è¦å¤„ç†çš„æ˜¯ policy.parameters() (æ­¤æ—¶å·²ç»æ˜¯ DDP åŒ…è£…åçš„)
    # DDP åŒ…è£…åï¼Œè®¿é—®åŸå§‹å‚æ•°åé€šå¸¸ä¼šæœ‰ "module." å‰ç¼€ï¼Œä½† named_parameters ä¼šè‡ªåŠ¨å¤„ç†
    param_groups = [
        {"params": [p for n, p in policy.named_parameters() if "backbone" in n and p.requires_grad], "lr": LR_BACKBONE},
        {"params": [p for n, p in policy.named_parameters() if "backbone" not in n and p.requires_grad], "lr": LR},
    ]
    optimizer = torch.optim.AdamW(param_groups, weight_decay=1e-4)

    if args.resume:
        if os.path.isfile(args.resume):
            if is_main_process(): logger.info(f"ğŸ”„ Resuming training from checkpoint: {args.resume}")
            # map_location å¿…é¡»æŒ‡å®šï¼Œå¦åˆ™ä¼šå…¨éƒ¨åŠ è½½åˆ° GPU 0
            checkpoint = torch.load(args.resume, map_location=device)
            new_state_dict = {}
            for k, v in checkpoint.items():
                name = k[7:] if k.startswith('module.') else k
                new_state_dict[name] = v

            # æ³¨æ„ï¼šå¿…é¡»ä½¿ç”¨ policy.module.load_state_dict è€Œä¸æ˜¯ policy.load_state_dict
            policy.module.load_state_dict(new_state_dict)
            if is_main_process(): logger.info(f"âœ… Loaded weights successfully.")
        else:
            if is_main_process(): logger.error(f"âŒ Checkpoint file not found: {args.resume}")
            return

    best_loss = float('inf')
    train_losses = []

    if N_OBS_STEPS == 1:
        NORM_MEAN = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)
        NORM_STD = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)
    else:
        NORM_MEAN = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 1, 3, 1, 1)
        NORM_STD = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 1, 3, 1, 1)

    total_start_time = time.time()

    for epoch in range(args.start_epoch, NUM_EPOCHS):
        # [DDP] 4. æ¯ä¸ª Epoch å¼€å§‹æ—¶å¿…é¡»è°ƒç”¨ï¼Œä»¥ç¡®ä¿æ•°æ®æ‰“ä¹±çš„éšæœºç§å­ä¸åŒ
        train_sampler.set_epoch(epoch)

        epoch_start = time.time()
        policy.train()
        epoch_loss, epoch_l1, epoch_kl = 0, 0, 0
        optimizer.zero_grad()

        # è¿›åº¦æ¡å»ºè®®ä»…åœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºï¼Œæˆ–è€…é™é»˜å¤„ç†
        # è¿™é‡Œç›´æ¥éå†
        for batch_idx, data in enumerate(train_loader):
            images_list, qpos, action, is_pad, speed_labels = data
            images_list = [x.to(device, non_blocking=True) for x in images_list]
            qpos = qpos.to(device, non_blocking=True)
            action = action.to(device, non_blocking=True)
            is_pad = is_pad.to(device, non_blocking=True)
            speed_labels = speed_labels.to(device, non_blocking=True)

            norm_imgs = [(img - NORM_MEAN) / NORM_STD for img in images_list]

            batch_input = {
                "observation.state": qpos, "action": action, "action_is_pad": is_pad,
                "observation.images": norm_imgs, "speed_label": speed_labels
            }

            pred_actions, (mu, logvar), pred_speed_logits = policy(batch_input)

            all_l1 = F.l1_loss(pred_actions, action, reduction='none')

            n_valid = (~is_pad).sum()
            if n_valid > 0:
                l1 = (all_l1 * ~is_pad.unsqueeze(-1)).sum() / (n_valid * ACTION_DIM + 1e-6)
            else:
                l1 = torch.tensor(0.0, device=device)

            total_kld, _, _ = kl_divergence(mu, logvar)
            kl_loss = total_kld[0]

            loss = l1 + KL_WEIGHT * kl_loss

            if pred_speed_logits is not None:
                loss_cls = F.cross_entropy(pred_speed_logits, speed_labels)
                loss += CLS_WEIGHT * loss_cls

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # [DDP] Loss è®°å½•å»ºè®®ï¼š
            # ä¸¥æ ¼æ¥è¯´åº”è¯¥ç”¨ dist.all_reduce å¹³å‡æ‰€æœ‰å¡çš„ loss æ‰èƒ½å¾—åˆ°å‡†ç¡®çš„å…¨å±€ loss
            # ä½†ä¸ºäº†æ€§èƒ½å’Œç®€å•ï¼Œé€šå¸¸åªæ‰“å° Rank 0 çš„ loss ä½œä¸ºå‚è€ƒå³å¯
            epoch_loss += loss.item()
            epoch_l1 += l1.item()
            epoch_kl += kl_loss.item()

        # è®¡ç®—å¹³å‡ Loss (è¿™é‡Œä»…åæ˜ å½“å‰ GPU çš„ Loss)
        avg_loss = epoch_loss / len(train_loader)

        # [DDP] å¯é€‰ï¼šåŒæ­¥æ‰€æœ‰å¡çš„ Loss å‡å€¼ä»¥ä¾¿ä¿å­˜æ¨¡å‹åˆ¤æ–­
        avg_loss_tensor = torch.tensor(avg_loss, device=device)
        dist.all_reduce(avg_loss_tensor, op=dist.ReduceOp.AVG)
        avg_loss_global = avg_loss_tensor.item()

        # ä»…åœ¨ Rank 0 è¿›è¡Œè®°å½•å’Œä¿å­˜
        if is_main_process():
            train_losses.append(avg_loss_global)
            epoch_dur = time.time() - epoch_start
            eta = str(timedelta(seconds=int((NUM_EPOCHS - epoch - 1) * (time.time() - total_start_time) / (epoch + 1))))

            logger.info(
                f"Epoch {epoch:04d} | Global Loss: {avg_loss_global:.5f} | Time: {epoch_dur:.1f}s | ETA: {eta}")

            if (epoch + 1) % 50 == 0:
                save_path = os.path.join(CKPT_DIR, f"policy_epoch_{epoch}.ckpt")
                # ä¿å­˜æ—¶å»ºè®®ä¿å­˜ policy.module (å»æ‰ DDP åŒ…è£…)ï¼Œæ–¹ä¾¿å•å¡æ¨ç†åŠ è½½
                torch.save(policy.module.state_dict(), save_path)
                save_train_loss_plot(RUN_DIR, train_losses, epoch)

            if avg_loss_global < best_loss:
                best_loss = avg_loss_global
                torch.save(policy.module.state_dict(), os.path.join(CKPT_DIR, "policy_best.ckpt"))
                logger.info(f"â­ Best Updated: {best_loss:.5f}")

    if is_main_process():
        logger.info("Training Done!")

    # [DDP] é”€æ¯è¿›ç¨‹ç»„
    dist.destroy_process_group()


if __name__ == '__main__':
    """
    torchrun --nproc_per_node=4 scripts/train_maact_2_video_with_speed_ddp.py --video
    CUDA_VISIBLE_DEVICES=0,2,3,4,5,6,7  torchrun --nproc_per_node=7 scripts/train_maact_2_video_with_speed_ddp.py --video --resume /root/Users/zhanguozhi/projects/replay_remote_ctrl/logs_maact/policy_epoch_699.ckpt --start_epoch=700
    """
    main()
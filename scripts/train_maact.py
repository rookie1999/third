import os
import sys
import glob
import pickle
import torch
import numpy as np
from torch.utils.data import DataLoader



current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from maact.common.configs.configuration_act import SpeedACTConfig
from maact.common.model.speed_act_modulate_full_model import SpeedACT
from dataset.efficient_ma_dataset import EfficientEpisodicDataset
from dataset.utils_norm import get_norm_stats

# å¯¼å…¥ä¸¤ç§ç­–ç•¥
# from policy.act.policy import ACTPolicy  # æ—§ç‰ˆ Standard ACT


def main():
    # =========================================================================
    # 1. æ ¸å¿ƒé…ç½®åŒºåŸŸ (ä¿®æ”¹è¿™é‡Œæ¥é€‚é…ä½ çš„è®­ç»ƒ)
    # =========================================================================

    # [å…³é”®å¼€å…³] True = è®­ç»ƒ MA-ACT (SpeedACT); False = è®­ç»ƒæ™®é€š ACT
    USE_SPEED_ACT = True

    # æ•°æ®ä¸ä¿å­˜è·¯å¾„
    DATA_DIR = r'F:\projects\lumos\data\20260109'  # ä½ çš„æ•°æ®è·¯å¾„
    CKPT_DIR = './checkpoints'  # æ¨¡å‹ä¿å­˜è·¯å¾„
    os.makedirs(CKPT_DIR, exist_ok=True)
    STATS_PATH = os.path.join(CKPT_DIR, 'dataset_stats.pkl')

    # è®­ç»ƒè¶…å‚æ•°
    NUM_EPOCHS = 5000
    BATCH_SIZE_PER_GPU = 8  # å®é™…å•æ¬¡å‰å‘çš„ Batch Size (å—æ˜¾å­˜é™åˆ¶)
    TARGET_BATCH_SIZE = 32  # ç›®æ ‡ Batch Size (é€šè¿‡æ¢¯åº¦ç´¯ç§¯å®ç°)
    ACCUMULATION_STEPS = max(1, TARGET_BATCH_SIZE // BATCH_SIZE_PER_GPU)

    LR = 1e-4
    CHUNK_SIZE = 100  # é¢„æµ‹æœªæ¥å¤šå°‘æ­¥

    # æœºå™¨äººä¸ç›¸æœºé…ç½®
    CAMERA_NAMES = ['cam_high']  # ä½ çš„æ•°æ®é›†ä¸­çš„ç›¸æœºåˆ—è¡¨
    MAIN_CAMERA_NAME = 'cam_high'  # MA-ACT éœ€è¦æŒ‡å®šä¸»ç›¸æœºè®¡ç®—å…‰æµ

    # çŠ¶æ€ç»´åº¦é…ç½®
    STATE_DIM = 14  # æœºæ¢°è‡‚çŠ¶æ€ç»´åº¦ (ä¾‹å¦‚ 7å…³èŠ‚ + 7é€Ÿåº¦)
    ACTION_DIM = 14  # åŠ¨ä½œç»´åº¦

    # YOLO æƒé‡è·¯å¾„ (ä»… MA-ACT éœ€è¦)
    YOLO_CKPT = r"F:\projects\lumos\ma_act\src\object_detection\object_detection_ckpt\yolov8n.pt"

    print(f"ğŸš€ Training Mode: {'MA-ACT (SpeedACT)' if USE_SPEED_ACT else 'Standard ACT'}")
    print(f"ğŸ“¦ Batch Size: {BATCH_SIZE_PER_GPU} (Accumulate to {TARGET_BATCH_SIZE})")

    # =========================================================================
    # 2. åˆå§‹åŒ– Dataset å’Œ DataLoader
    # =========================================================================

    # è‡ªåŠ¨è®¡ç®—ç»Ÿè®¡æ•°æ® (Mean/Std)
    if not os.path.exists(STATS_PATH):
        print(f"Computing stats from {DATA_DIR}...")
        stats = get_norm_stats(DATA_DIR)
        with open(STATS_PATH, 'wb') as f:
            pickle.dump(stats, f)
    else:
        print(f"Loading stats from {STATS_PATH}...")
        with open(STATS_PATH, 'rb') as f:
            stats = pickle.load(f)

    dataset_path_list = glob.glob(os.path.join(DATA_DIR, '*.hdf5'))

    # [å…³é”®] æ ¹æ®æ¨¡å¼è®¾å®š n_obs_steps
    # MA-ACT éœ€è¦è‡³å°‘ 2 å¸§æ¥è®¡ç®—å…‰æµï¼›ACT åªéœ€è¦ 1 å¸§
    current_n_obs_steps = 2 if USE_SPEED_ACT else 1

    train_dataset = EfficientEpisodicDataset(
        dataset_path_list,
        stats,
        camera_names=CAMERA_NAMES,
        chunk_size=CHUNK_SIZE,
        n_obs_steps=current_n_obs_steps
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE_PER_GPU,
        shuffle=True,
        pin_memory=True,
        num_workers=4,
        prefetch_factor=2
    )

    # =========================================================================
    # 3. åˆå§‹åŒ–æ¨¡å‹ (Policy)
    # =========================================================================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    if USE_SPEED_ACT:
        # --- åˆå§‹åŒ– MA-ACT ---
        config = SpeedACTConfig(
            dim_model=512,
            n_heads=8,
            dim_feedforward=3200,
            n_encoder_layers=4,
            n_decoder_layers=1,
            chunk_size=CHUNK_SIZE,
            n_obs_steps=current_n_obs_steps,  # å¿…é¡» >= 2

            # è§†è§‰é…ç½®
            image_features={cam: (3, 480, 640) for cam in CAMERA_NAMES},  # å‡è®¾å›¾ç‰‡éƒ½æ˜¯ 480x640
            main_camera=MAIN_CAMERA_NAME,

            # çŠ¶æ€é…ç½®
            robot_state_feature=(STATE_DIM,),  # æ³¨æ„è¿™æ˜¯ tuple
            action_feature=(ACTION_DIM,),

            # åŠŸèƒ½å¼€å…³
            use_optical_flow=True,
            object_detection_ckpt_path=YOLO_CKPT,

            # å…‰æµå‚æ•°
            cropped_flow_h=64,
            cropped_flow_w=64,

            # ç¼ºå¤±å±æ€§è¡¥å…¨ (é˜²æ­¢æŠ¥é”™)
            feedforward_activation="relu",
            pre_norm=False
        )
        policy = SpeedACT(config).to(device)
    # else:
    #     # --- åˆå§‹åŒ– Standard ACT ---
    #     policy = ACTPolicy(
    #         action_dim=ACTION_DIM,
    #         state_dim=STATE_DIM,
    #         hidden_dim=512,
    #         chunk_size=CHUNK_SIZE,
    #         # å¦‚æœä½ æœ‰ç‰¹å®šçš„ VAE æˆ– Backbone å‚æ•°ï¼Œè¯·åœ¨è¿™é‡Œæ·»åŠ 
    #     ).to(device)

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(policy.parameters(), lr=LR, weight_decay=1e-4)

    # =========================================================================
    # 4. è®­ç»ƒå¾ªç¯
    # =========================================================================
    best_loss = float('inf')

    for epoch in range(NUM_EPOCHS):
        policy.train()
        epoch_loss = 0
        optimizer.zero_grad()

        for batch_idx, data in enumerate(train_loader):
            # è§£åŒ…æ•°æ® (æ¥è‡ª efficient_dataset.py çš„ __getitem__)
            # images_list: å¦‚æœ n_obs=1 æ˜¯ [(B,C,H,W)...], å¦‚æœ n_obs=2 æ˜¯ [(B,T,C,H,W)...]
            images_list, qpos, action, is_pad = data

            # æ•°æ®ç§»åŠ¨åˆ° GPU
            images_list = [x.to(device, non_blocking=True) for x in images_list]
            qpos = qpos.to(device, non_blocking=True)
            action = action.to(device, non_blocking=True)
            is_pad = is_pad.to(device, non_blocking=True)

            # --- åˆ†æ”¯ï¼šæ•°æ®è¾“å…¥æ¨¡å‹ ---
            if USE_SPEED_ACT:
                # [MA-ACT åˆ†æ”¯] æ„é€ å­—å…¸è¾“å…¥
                batch_input = {
                    "observation.state": qpos,  # (B, T, D)
                    "action": action,  # (B, Chunk, D)
                    "action_is_pad": is_pad,  # (B, Chunk)
                    "observation.images": images_list  # List[(B, T, C, H, W)]
                }
                # æ‰‹åŠ¨æ³¨å…¥ä¸»ç›¸æœºæ•°æ®ç”¨äºå…‰æµè®¡ç®—
                # å‡è®¾ config.main_camera å¯¹åº”çš„å°±æ˜¯ images_list[0] (å¦‚æœæ˜¯å•æ‘„)
                # å¦‚æœæ˜¯å¤šæ‘„ï¼Œè¯·æ ¹æ® camera_names çš„é¡ºåºç´¢å¼•ï¼Œè¿™é‡Œé»˜è®¤å–ç¬¬ä¸€ä¸ª
                batch_input[MAIN_CAMERA_NAME] = images_list[0]

                loss_dict = policy(batch_input)

            else:
                # [Standard ACT åˆ†æ”¯] å‚æ•°åˆ—è¡¨è¾“å…¥
                # ACT é€šå¸¸åªæ¥å—å•å¼ å›¾ç‰‡ï¼ˆæˆ–è€…å¤šå¼  concatï¼‰
                # è¿™é‡Œå‡è®¾å–ç¬¬ä¸€ä¸ªç›¸æœºçš„å›¾åƒ
                image_input = images_list[0]  # (B, C, H, W)

                loss_dict = policy(qpos, image_input, actions=action, is_pad=is_pad)

            # --- Loss å¤„ç†ä¸åå‘ä¼ æ’­ ---
            loss = loss_dict['loss']

            # æ¢¯åº¦ç´¯ç§¯ï¼šLoss é™¤ä»¥æ­¥æ•°
            loss_scaled = loss / ACCUMULATION_STEPS
            loss_scaled.backward()

            # è®°å½•çœŸå® Loss
            epoch_loss += loss.item()

            # æ‰§è¡Œæ›´æ–°
            if (batch_idx + 1) % ACCUMULATION_STEPS == 0:
                optimizer.step()
                optimizer.zero_grad()

        # å¤„ç† Epoch ç»“å°¾å‰©ä½™çš„æ¢¯åº¦
        if len(train_loader) % ACCUMULATION_STEPS != 0:
            optimizer.step()
            optimizer.zero_grad()

        # æ‰“å°æ—¥å¿—
        avg_loss = epoch_loss / len(train_loader)
        print(f"Epoch {epoch}: Loss = {avg_loss:.5f}")

        # ä¿å­˜æƒé‡
        if epoch % 500 == 0:
            ckpt_name = f"policy_epoch_{epoch}_ma_act.ckpt" if USE_SPEED_ACT else f"policy_epoch_{epoch}_act.ckpt"
            save_path = os.path.join(CKPT_DIR, ckpt_name)
            torch.save(policy.state_dict(), save_path)

        # ä¿å­˜æœ€ä½³æƒé‡
        if avg_loss < best_loss:
            best_loss = avg_loss
            ckpt_name = "policy_best_ma_act.ckpt" if USE_SPEED_ACT else "policy_best_act.ckpt"
            save_path = os.path.join(CKPT_DIR, ckpt_name)
            torch.save(policy.state_dict(), save_path)
            print(f"âœ… Best model saved with loss {best_loss:.5f}")


if __name__ == '__main__':
    main()
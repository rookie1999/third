import glob
import os
import pickle
import sys

import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

# å¼•å…¥ MA-ACT ç›¸å…³æ¨¡å—
from policy.maact.common.configs.configuration_act import SpeedACTConfig
from policy.maact.common.model.speed_act_modulate_full_model import SpeedACT
from dataset.efficient_ma_dataset import EfficientEpisodicDataset
from dataset.utils_norm import get_norm_stats


def kl_divergence(mu, logvar):
    """
    è®¡ç®— KL æ•£åº¦ Loss (VAE å¿…è¦ç»„ä»¶)
    """
    batch_size = mu.size(0)
    assert batch_size != 0
    if mu.data.ndimension() == 4:
        mu = mu.view(mu.size(0), mu.size(1))
    if logvar.data.ndimension() == 4:
        logvar = logvar.view(logvar.size(0), logvar.size(1))

    klds = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp())
    total_kld = klds.sum(1).mean(0, True)
    dimension_wise_kld = klds.mean(0)
    mean_kld = klds.mean(1).mean(0, True)

    return total_kld, dimension_wise_kld, mean_kld


def main():
    # =========================================================================
    # 1. æ ¸å¿ƒé…ç½®åŒºåŸŸ
    # =========================================================================

    # è·¯å¾„é…ç½®
    DATA_DIR = r'F:\projects\lumos\data\20260109'  # æ•°æ®é›†è·¯å¾„
    CKPT_DIR = './checkpoints_maact'  # æ¨¡å‹ä¿å­˜è·¯å¾„
    os.makedirs(CKPT_DIR, exist_ok=True)
    STATS_PATH = os.path.join(CKPT_DIR, 'dataset_stats.pkl')

    # YOLO æƒé‡è·¯å¾„ (MA-ACT è®¡ç®—å…‰æµ Mask å¿…éœ€)
    YOLO_CKPT = r"F:\projects\lumos\ma_act\src\object_detection\object_detection_ckpt\yolov8n.pt"

    # è®­ç»ƒè¶…å‚æ•°
    NUM_EPOCHS = 5000
    BATCH_SIZE_PER_GPU = 8  # å•å¡å®é™… Batch Size
    TARGET_BATCH_SIZE = 32  # ç›®æ ‡ Batch Size (æ¢¯åº¦ç´¯ç§¯)
    ACCUMULATION_STEPS = max(1, TARGET_BATCH_SIZE // BATCH_SIZE_PER_GPU)

    LR = 1e-4  # å…¨å±€(Transformer)å­¦ä¹ ç‡
    LR_BACKBONE = 1e-5  # Backbone ä¸“ç”¨è¾ƒå°å­¦ä¹ ç‡

    CHUNK_SIZE = 100  # åŠ¨ä½œé¢„æµ‹é•¿åº¦
    KL_WEIGHT = 10.0  # KL Loss æƒé‡ç³»æ•°

    # æœºå™¨äººä¸ç›¸æœºé…ç½®
    CAMERA_NAMES = ['cam_high']  # æ•°æ®é›†ä¸­çš„ç›¸æœºåˆ—è¡¨
    MAIN_CAMERA_NAME = 'cam_high'  # ç”¨äºè®¡ç®—å…‰æµçš„ä¸»ç›¸æœº

    # [å…³é”®ä¿®æ­£] ç»´åº¦éœ€åŒ¹é…æ‚¨çš„æ•°æ®é›† (ä¹‹å‰æŠ¥é”™æ˜¯å› ä¸ºè¿™é‡Œå¡«äº†14ï¼Œä½†æ•°æ®æ˜¯7)
    STATE_DIM = 7  # æœºæ¢°è‡‚çŠ¶æ€ç»´åº¦
    ACTION_DIM = 7  # åŠ¨ä½œç»´åº¦

    # MA-ACT å¿…éœ€å†å²å¸§
    N_OBS_STEPS = 2  # è§‚å¯Ÿå†å²æ­¥æ•° (>=2)

    print(f"ğŸš€ Training Mode: MA-ACT (SpeedACT)")
    print(f"ğŸ“¦ Batch Size: {BATCH_SIZE_PER_GPU} (Accumulate to {TARGET_BATCH_SIZE})")
    print(f"ğŸ”§ LR: {LR}, Backbone LR: {LR_BACKBONE}")
    print(f"ğŸ“ Dimensions: State={STATE_DIM}, Action={ACTION_DIM}")

    # =========================================================================
    # 2. æ•°æ®é›†å‡†å¤‡
    # =========================================================================

    if not os.path.exists(STATS_PATH):
        print(f"Computing stats from {DATA_DIR}...")
        stats = get_norm_stats(DATA_DIR)
        with open(STATS_PATH, 'wb') as f:
            pickle.dump(stats, f)
    else:
        print(f"Loading stats from {STATS_PATH}...")
        with open(STATS_PATH, 'rb') as f:
            stats = pickle.load(f)

    dataset_path_list = glob.glob(os.path.join(DATA_DIR, '*.hdf5'))

    train_dataset = EfficientEpisodicDataset(
        dataset_path_list,
        stats,
        camera_names=CAMERA_NAMES,
        chunk_size=CHUNK_SIZE,
        n_obs_steps=N_OBS_STEPS
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE_PER_GPU,
        shuffle=True,
        pin_memory=True,
        num_workers=4,
        prefetch_factor=2
    )

    # =========================================================================
    # 3. åˆå§‹åŒ– MA-ACT æ¨¡å‹
    # =========================================================================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    config = SpeedACTConfig(
        dim_model=512,
        n_heads=8,
        dim_feedforward=3200,
        n_encoder_layers=4,
        n_decoder_layers=1,
        chunk_size=CHUNK_SIZE,
        n_obs_steps=N_OBS_STEPS,

        image_features={cam: (3, 480, 640) for cam in CAMERA_NAMES},
        main_camera=MAIN_CAMERA_NAME,

        robot_state_feature=(STATE_DIM,),
        action_feature=(ACTION_DIM,),

        use_optical_flow=True,
        object_detection_ckpt_path=YOLO_CKPT,
        cropped_flow_h=64,
        cropped_flow_w=64,

        feedforward_activation="relu",
        pre_norm=False
    )

    policy = SpeedACT(config).to(device)

    # -----------------------------------------------------------
    # ä¼˜åŒ–å™¨å‚æ•°åˆ†ç»„ (Backbone ä½¿ç”¨ä½å­¦ä¹ ç‡)
    # -----------------------------------------------------------
    param_groups = [
        # 1. Backbone å‚æ•° (LR = 1e-5)
        {
            "params": [p for n, p in policy.named_parameters() if "backbone" in n and p.requires_grad],
            "lr": LR_BACKBONE,
        },
        # 2. å…¶ä»–æ‰€æœ‰å‚æ•° (Transformer, Heads ç­‰) (LR = 1e-4)
        {
            "params": [p for n, p in policy.named_parameters() if "backbone" not in n and p.requires_grad],
            "lr": LR,
        },
    ]
    optimizer = torch.optim.AdamW(param_groups, weight_decay=1e-4)

    # =========================================================================
    # 4. è®­ç»ƒå¾ªç¯
    # =========================================================================
    best_loss = float('inf')
    train_losses = []

    # å®šä¹‰å½’ä¸€åŒ–å‚æ•° (ImageNet Stats)
    # å½¢çŠ¶: (1, 1, 3, 1, 1) ç”¨äºå¹¿æ’­åŒ¹é… (Batch, Time, Channel, Height, Width)
    NORM_MEAN = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 1, 3, 1, 1)
    NORM_STD = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 1, 3, 1, 1)

    for epoch in range(NUM_EPOCHS):
        policy.train()
        epoch_loss = 0
        optimizer.zero_grad()

        for batch_idx, data in enumerate(train_loader):
            # è§£åŒ…æ•°æ® (images_list åŒ…å«å¤šå¸§: B, T, C, H, W)
            images_list, qpos, action, is_pad = data

            # æ•°æ®ç§»åŠ¨åˆ° GPU
            # æ³¨æ„ï¼šimages_list é‡Œçš„æ•°æ®æ­¤æ—¶æ˜¯ [0, 1] èŒƒå›´çš„ float
            images_list = [x.to(device, non_blocking=True) for x in images_list]
            qpos = qpos.to(device, non_blocking=True)
            action = action.to(device, non_blocking=True)
            is_pad = is_pad.to(device, non_blocking=True)

            # -----------------------------------------------------------
            # å›¾åƒå½’ä¸€åŒ– (Normalize to ImageNet Stats)
            # -----------------------------------------------------------
            normalized_images_list = []
            for img in images_list:
                # img shape: (B, T, 3, H, W)
                # æ‰§è¡Œå¹¿æ’­è¿ç®—
                norm_img = (img - NORM_MEAN) / NORM_STD
                normalized_images_list.append(norm_img)

            # æ„é€ è¾“å…¥å­—å…¸
            batch_input = {
                "observation.state": qpos,
                "action": action,
                "action_is_pad": is_pad,
                "observation.images": normalized_images_list  # ä½¿ç”¨å½’ä¸€åŒ–åçš„å›¾ç‰‡
            }
            # ä¸»ç›¸æœºç”¨äºå…‰æµ
            batch_input[MAIN_CAMERA_NAME] = normalized_images_list[0]

            # -----------------------------------------------------------
            # Loss è®¡ç®— (L1 + KL)
            # -----------------------------------------------------------

            # å‰å‘ä¼ æ’­
            pred_actions, (mu, logvar) = policy(batch_input)

            # L1 Loss (Masked)
            all_l1 = F.l1_loss(pred_actions, action, reduction='none')
            l1 = (all_l1 * ~is_pad.unsqueeze(-1)).mean()

            # KL Loss
            total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)
            kl_loss = total_kld[0]

            # æ€» Loss
            loss = l1 + KL_WEIGHT * kl_loss

            # æ¢¯åº¦ç´¯ç§¯
            loss_scaled = loss / ACCUMULATION_STEPS
            loss_scaled.backward()

            epoch_loss += loss.item()

            if (batch_idx + 1) % ACCUMULATION_STEPS == 0:
                optimizer.step()
                optimizer.zero_grad()

        # å¤„ç† Epoch å‰©ä½™æ¢¯åº¦
        if len(train_loader) % ACCUMULATION_STEPS != 0:
            optimizer.step()
            optimizer.zero_grad()

        # æ—¥å¿—è®°å½•
        avg_loss = epoch_loss / len(train_loader)
        train_losses.append(avg_loss)
        print(f"Epoch {epoch}: Loss = {avg_loss:.5f} (L1={l1.item():.4f}, KL={kl_loss.item():.4f})")

        # å®šæœŸä¿å­˜ä¸ç»˜å›¾
        if epoch % 500 == 0:
            save_path = os.path.join(CKPT_DIR, f"policy_epoch_{epoch}.ckpt")
            torch.save(policy.state_dict(), save_path)

            # ç®€å•ç»˜å›¾
            plt.figure()
            plt.plot(train_losses)
            plt.title("Training Loss")
            plt.xlabel("Epoch")
            plt.ylabel("Loss")
            plt.savefig(os.path.join(CKPT_DIR, 'loss_curve.png'))
            plt.close()

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss
            save_path = os.path.join(CKPT_DIR, "policy_best.ckpt")
            torch.save(policy.state_dict(), save_path)
            print(f"âœ… Best model saved with loss {best_loss:.5f}")

    print("Training Done!")


if __name__ == '__main__':
    main()
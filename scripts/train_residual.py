import os
import sys
import time
import pickle
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from datetime import timedelta
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

# === å¼•å…¥æ¨¡å— ===
# 1. å¼•å…¥ä¹‹å‰æ”¹å¥½çš„ Hybrid Dataset
from dataset.efficient_ma_video_dataset import VideoBasedEfficientMADataset
from dataset.utils_norm import get_norm_stats

# 2. å¼•å…¥æ¨¡å‹
from policy.maact.common.configs.configuration_act import SpeedACTConfig
from policy.maact.common.model.speed_act_modulate_full_model import SpeedACT
# å‡è®¾ä½ æŠŠ Residual ç±»æ”¾åœ¨äº†è¿™ä¸ªä½ç½®ï¼Œæˆ–è€…ä½ å¯ä»¥ç›´æ¥æŠŠ Residual ç±»å®šä¹‰è´´åœ¨è¿™é‡Œ
from policy.maact.common.model.residual_speed_act import ResidualSpeedACT

# 3. å·¥å…·
from scripts.utils_train import setup_logger, get_run_dirs, save_train_loss_plot


def compute_awac_weights(speed_labels, temperature=1.0):
    """
    æ ¹æ®é€Ÿåº¦æ ‡ç­¾è®¡ç®— AWAC æƒé‡ã€‚
    å‡è®¾ï¼šé€Ÿåº¦è¶Šå¿« (Level 2) -> éš¾åº¦è¶Šé«˜ -> æˆåŠŸåçš„ Reward è¶Šé«˜ -> æƒé‡è¶Šå¤§
    """
    # ç®€å•çš„æ˜ å°„é€»è¾‘ï¼š
    # Level 0 (Slow)   -> Advantage = 0.0
    # Level 1 (Normal) -> Advantage = 1.0
    # Level 2 (Fast)   -> Advantage = 2.0
    advantage = speed_labels.float()

    # è®¡ç®—æƒé‡ w = exp(A / T)
    weights = torch.exp(advantage / temperature)

    # å½’ä¸€åŒ–æˆ–æˆªæ–­ï¼Œé˜²æ­¢æƒé‡è¿‡å¤§å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
    weights = torch.clamp(weights, max=10.0)
    return weights


def main():
    # ==========================
    # 1. é…ç½®åŒºåŸŸ
    # ==========================
    # é¢„è®­ç»ƒå¥½çš„ SpeedACT æƒé‡è·¯å¾„ (å¿…é¡»ä¿®æ”¹ï¼)
    PRETRAINED_CKPT = r'F:\projects\lumos\logs_maact\run_001\checkpoints\policy_best.ckpt'
    DATA_DIR = r'F:\projects\lumos\data\20260109'

    # è®­ç»ƒå‚æ•°
    BATCH_SIZE = 16
    NUM_EPOCHS = 200  # æ®‹å·®å¾®è°ƒé€šå¸¸å¾ˆå¿«ï¼Œä¸éœ€è¦å¤ªå¤šè½®
    LR = 1e-4  # å­¦ä¹ ç‡
    CHUNK_SIZE = 50

    # æ··åˆç¼“å­˜é…ç½®
    MAX_PRELOAD_EPISODES = 50

    # AWAC æ¸©åº¦ç³»æ•° (è¶Šå°ï¼Œå¯¹é«˜é€Ÿæ•°æ®çš„åå¥½è¶Šæç«¯)
    AWAC_TEMPERATURE = 1.0

    # ç›®å½•è®¾ç½®
    RUN_DIR, CKPT_DIR, RUN_NAME = get_run_dirs("./logs_residual")
    logger = setup_logger(RUN_DIR, name="ResidualRL")
    STATS_PATH = os.path.join(CKPT_DIR, 'dataset_stats.pkl')

    logger.info(f"ğŸš€ Residual RL Training Started! Run ID: {RUN_NAME}")

    # ==========================
    # 2. å‡†å¤‡æ•°æ®
    # ==========================
    # ç»Ÿè®¡æ•°æ®
    if not os.path.exists(STATS_PATH):
        stats = get_norm_stats(DATA_DIR)
        with open(STATS_PATH, 'wb') as f:
            pickle.dump(stats, f)
    else:
        with open(STATS_PATH, 'rb') as f:
            stats = pickle.load(f)

    # åŠ è½½æ•°æ®é›† (ä½¿ç”¨ Video Dataset)
    import glob
    dataset_path_list = glob.glob(os.path.join(DATA_DIR, '*.hdf5'))

    train_dataset = VideoBasedEfficientMADataset(
        dataset_path_list, stats, camera_names=['cam_high'],
        chunk_size=CHUNK_SIZE, n_obs_steps=2,  # æ³¨æ„ï¼šResidual å¯èƒ½ä¼šç”¨åˆ°å¤šå¸§
        max_preload_episodes=MAX_PRELOAD_EPISODES
    )

    train_loader = DataLoader(
        train_dataset, batch_size=BATCH_SIZE, shuffle=True,
        pin_memory=True, num_workers=4, prefetch_factor=2
    )

    # ==========================
    # 3. å‡†å¤‡æ¨¡å‹
    # ==========================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # A. åˆå§‹åŒ–é…ç½® (ç¡®ä¿ä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€è‡´)
    config = SpeedACTConfig(
        state_dim=8, action_dim=8, chunk_size=CHUNK_SIZE,
        n_obs_steps=2,  # å¿…é¡»ä¸ Dataset ä¸€è‡´
        # ... å…¶ä»–å‚æ•°æ ¹æ®ä½ çš„å®é™…æƒ…å†µå¡«å†™ ...
    )

    # B. åŠ è½½åŸºåº§æ¨¡å‹
    logger.info(f"Loading base model from {PRETRAINED_CKPT}...")
    base_model = SpeedACT(config)
    state_dict = torch.load(PRETRAINED_CKPT, map_location='cpu')
    base_model.load_state_dict(state_dict)
    base_model.to(device)

    # C. åˆå§‹åŒ–æ®‹å·®æ¨¡å‹
    model = ResidualSpeedACT(base_model, config).to(device)

    # D. ä¼˜åŒ–å™¨ (å…³é”®ï¼šåªä¼˜åŒ– residual_mlp)
    # base_policy çš„å‚æ•°å·²ç»åœ¨ ResidualSpeedACT.__init__ é‡Œè®¾ä¸º requires_grad=False äº†
    # ä½†ä¸ºäº†åŒé‡ä¿é™©ï¼Œè¿™é‡Œæ˜¾å¼è¿‡æ»¤
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.AdamW(trainable_params, lr=LR, weight_decay=1e-4)

    logger.info(f"Trainable Parameters: {sum(p.numel() for p in trainable_params)}")
    logger.info("Base Policy is FROZEN. ğŸ¥¶")

    # ==========================
    # 4. è®­ç»ƒå¾ªç¯
    # ==========================
    best_loss = float('inf')
    train_losses = []
    total_start_time = time.time()

    loss_fn = nn.MSELoss(reduction='none')  # ä½¿ç”¨ none ä»¥ä¾¿æ‰‹åŠ¨åŠ æƒ

    for epoch in range(NUM_EPOCHS):
        model.train()  # è¿™é‡Œçš„ train() åªä¼šå¼€å¯ residual çš„ dropoutï¼Œbase ä¾ç„¶æ˜¯ eval
        epoch_loss = 0
        optimizer.zero_grad()

        epoch_start = time.time()

        for batch_idx, data in enumerate(train_loader):
            # 1. è§£åŒ…æ•°æ® (æ³¨æ„ Dataset è¿”å›äº† speed_label)
            image_tensors, qpos, action_gt, is_pad, speed_labels = data

            # æ„é€  batch å­—å…¸é€‚é… model æ¥å£
            batch = {
                "observation.images": image_tensors,  # list of tensors
                "observation.state": qpos.to(device),
                "action": action_gt.to(device),
                "action_is_pad": is_pad.to(device),
                # ç”¨äº SpeedACT å†…éƒ¨é€»è¾‘ï¼Œè™½ç„¶è¿™é‡Œæˆ‘ä»¬ä¸ç›´æ¥ç”¨å®ƒçš„ Loss
                "cam_high": image_tensors[0].to(device)
            }

            gt_action = action_gt.to(device)
            speed_labels = speed_labels.to(device)

            # 2. Forward (è·å–å åŠ åçš„åŠ¨ä½œ)
            # pred_action = Base + Residual
            pred_action = model(batch)

            # 3. è®¡ç®— AWAC Loss
            # A. åŸºç¡€ MSE Loss
            # (B, Chunk, Dim)
            raw_loss = loss_fn(pred_action, gt_action)
            # å¯¹ Chunk å’Œ Dim ç»´åº¦æ±‚å¹³å‡ï¼Œä¿ç•™ Batch ç»´åº¦ -> (B,)
            mse_per_sample = raw_loss.mean(dim=(1, 2))

            # B. è®¡ç®—æƒé‡ (Importance Sampling / Advantage Weighting)
            # é€Ÿåº¦è¶Šå¿« -> æƒé‡è¶Šå¤§
            weights = compute_awac_weights(speed_labels, temperature=AWAC_TEMPERATURE)

            # C. åŠ æƒæœ€ç»ˆ Loss
            loss = (mse_per_sample * weights).mean()

            # 4. Backward
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            epoch_loss += loss.item()

        # ==========================
        # 5. æ—¥å¿—ä¸ä¿å­˜
        # ==========================
        avg_loss = epoch_loss / len(train_loader)
        train_losses.append(avg_loss)

        epoch_dur = time.time() - epoch_start
        eta = str(timedelta(seconds=int((NUM_EPOCHS - epoch - 1) * (time.time() - total_start_time) / (epoch + 1))))

        logger.info(f"Epoch {epoch:04d} | AWAC Loss: {avg_loss:.5f} | Time: {epoch_dur:.1f}s | ETA: {eta}")

        if epoch % 50 == 0:  # æ®‹å·®è®­ç»ƒé€šå¸¸å­˜å¾—ä¸éœ€è¦é‚£ä¹ˆé¢‘ï¼Œæˆ–è€…ä½ å¯ä»¥æ”¹é¢‘ä¸€ç‚¹
            torch.save(model.state_dict(), os.path.join(CKPT_DIR, f"residual_epoch_{epoch}.ckpt"))
            save_train_loss_plot(RUN_DIR, train_losses, epoch)

        if avg_loss < best_loss:
            best_loss = avg_loss
            # è¿™é‡Œä¿å­˜çš„æ˜¯æ•´ä¸ª ResidualSpeedACT çš„å‚æ•°ï¼ˆåŒ…å« Frozen çš„ Baseï¼‰
            # å®é™…éƒ¨ç½²æ—¶ï¼Œä½ ä¹Ÿå¯ä»¥åªä¿å­˜ residual_mlp çš„éƒ¨åˆ†ï¼Œçœç©ºé—´
            torch.save(model.state_dict(), os.path.join(CKPT_DIR, "residual_best.ckpt"))
            logger.info(f"â­ Best Updated: {best_loss:.5f}")

    logger.info("Residual Training Done!")


if __name__ == '__main__':
    main()
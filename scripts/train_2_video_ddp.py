import argparse
import glob
import os
import pickle
import sys
import time
import json
from datetime import timedelta

import torch
import torch.nn as nn
import torch.distributed as dist  # [DDP] å¼•å…¥åˆ†å¸ƒå¼æ¨¡å—
from torch.nn.parallel import DistributedDataParallel as DDP  # [DDP]
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler  # [DDP] å¼•å…¥åˆ†å¸ƒå¼é‡‡æ ·å™¨

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from policy.act.policy import ACTPolicy
from dataset.utils_norm import get_norm_stats
from scripts.utils_train import setup_logger, get_run_dirs, save_train_loss_plot

from dataset.efficient_dataset import EfficientEpisodicDataset
from dataset.efficient_video_dataset import VideoBasedEfficientDataset


# [DDP] å·¥å…·å‡½æ•°ï¼šåˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ (Rank 0)
def is_main_process():
    return not dist.is_initialized() or dist.get_rank() == 0


def main():
    parser = argparse.ArgumentParser(description="ACT DDP Training Script")
    parser.add_argument('--video', action='store_true', help='Use video dataset (load from .mp4)')
    parser.add_argument('--fisheye', action='store_true', help='Whether use fisheye camera or not')
    parser.add_argument('--resume', type=str, default=None, help='Path to checkpoint to resume from')
    parser.add_argument('--start_epoch', type=int, default=0, help='Epoch to start from')
    args = parser.parse_args()

    # [DDP] 1. åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    # torchrun å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨è®¾ç½® LOCAL_RANK ç¯å¢ƒå˜é‡
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    torch.cuda.set_device(local_rank)
    dist.init_process_group(backend='nccl', init_method='env://')
    device = torch.device(f"cuda:{local_rank}")

    global_rank = dist.get_rank()
    world_size = dist.get_world_size()

    # è·¯å¾„é…ç½®
    if args.video:
        DATA_DIR = r'/home/zgz/projects/lumos/train_data/episode'  # ç¡®ä¿å¤šå¡æœºå™¨è·¯å¾„æ­£ç¡®
    else:
        DATA_DIR = r'/home/zgz/projects/lumos/data/20260109'  # Linux è·¯å¾„

    # [DDP] ä»…åœ¨ä¸»è¿›ç¨‹ä¸­è®¾ç½® Logger å’Œåˆ›å»ºæ–‡ä»¶å¤¹
    logger = None
    CKPT_DIR = None
    RUN_DIR = None
    STATS_PATH = None
    RUN_NAME = None

    if is_main_process():
        RUN_DIR, CKPT_DIR, RUN_NAME = get_run_dirs("./logs_act")
        STATS_PATH = os.path.join(CKPT_DIR, 'dataset_stats.pkl')
        logger = setup_logger(RUN_DIR, name="ACT")

        mode_str = "VIDEO-Based" if args.video else "HDF5-RAM-Based"
        logger.info(f"ğŸš€ ACT DDP Training Started! Mode: [{mode_str}] | Run ID: {RUN_NAME}")
        logger.info(f"Using {world_size} GPUs. Data Dir: {DATA_DIR}")
    else:
        # éä¸»è¿›ç¨‹ä¸æ‰“å° Logï¼Œæˆ–è€…å¯ä»¥è®¾ç½®ä¸€ä¸ª Dummy Logger
        pass

    # è¶…å‚æ•°
    NUM_EPOCHS = 1000
    # [DDP] Batch Size è¿™é‡ŒæŒ‡æ¯å¼ å¡çš„ batch size
    # å¦‚æœåŸæ¥æ€» Batch Size æ˜¯ 64ï¼Œç°åœ¨æœ‰ 4 å¼ å¡ï¼Œè¿™é‡Œè®¾ä¸º 16 å³å¯ä¿æŒæ€»æ•°ä¸å˜ï¼›æˆ–è€…è®¾ä¸º 64 åŠ é€Ÿè®­ç»ƒ
    BATCH_SIZE = 64
    LR = 1e-5
    CHUNK_SIZE = 50
    KL_WEIGHT = 10.0
    CAMERA_NAMES = ['cam_high']

    num_workers = 6

    dataset_path_list = glob.glob(os.path.join(DATA_DIR, '*.hdf5'))

    # [DDP] ç»Ÿè®¡æ•°æ® (Stats) åŒæ­¥
    # ç­–ç•¥ï¼šRank 0 è®¡ç®— -> å¹¿æ’­ç»™å…¶ä»– Rank
    stats = None
    if is_main_process():
        if len(dataset_path_list) == 0:
            logger.error(f"No HDF5 files found in {DATA_DIR}. Check your path!")
            sys.exit(1)

        logger.info(f"Computing/Loading stats from: {DATA_DIR} ...")
        # å®é™…é¡¹ç›®ä¸­ï¼Œå»ºè®® stats é¢„å…ˆç®—å¥½å­˜å›ºå®šä½ç½®ï¼Œé¿å…æ¯æ¬¡è®¡ç®—
        # è¿™é‡Œä¸ºäº†å…¼å®¹ï¼Œä¾ç„¶å®æ—¶è®¡ç®—æˆ–ä»æœ¬æ¬¡ Run ç›®å½•åŠ è½½
        stats = get_norm_stats(DATA_DIR)

        # ä¿å­˜ä¸€ä»½åˆ°æœ¬æ¬¡ Log ç›®å½•å¤‡ä»½
        with open(STATS_PATH, 'wb') as f:
            pickle.dump(stats, f)

    TARGET_SIZE = (640, 480)
    if args.fisheye:
        TARGET_SIZE = (480, 480)

    # å¹¿æ’­ stats å¯¹è±¡
    stats_list = [stats]
    dist.broadcast_object_list(stats_list, src=0)
    stats = stats_list[0]

    # ç­‰å¾…åŒæ­¥
    dist.barrier()

    STATE_DIM = stats['qpos_mean'].shape[0]
    ACTION_DIM = stats['action_mean'].shape[0]
    if STATE_DIM == 7:
        logger.info("Use rpy for training")
    elif STATE_DIM == 10:
        logger.info("Use rot6d for training")


    if args.video:
        if is_main_process(): logger.info("Initializing VideoBasedEfficientDataset...")
        train_dataset = VideoBasedEfficientDataset(
            dataset_path_list, stats, camera_names=CAMERA_NAMES, chunk_size=CHUNK_SIZE,
            target_size=TARGET_SIZE
        )
    else:
        if is_main_process(): logger.info("Initializing EfficientEpisodicDataset...")
        train_dataset = EfficientEpisodicDataset(
            dataset_path_list, stats, camera_names=CAMERA_NAMES, chunk_size=CHUNK_SIZE
        )

    # [DDP] 2. ä½¿ç”¨ DistributedSampler
    # shuffle=True è¡¨ç¤ºæ¯ä¸ª Epoch æ•°æ®ä¼šæ‰“ä¹±
    train_sampler = DistributedSampler(train_dataset, shuffle=True)

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,  # [DDP] å¿…é¡»ä¸º Falseï¼Œshuffle äº¤ç»™ sampler
        sampler=train_sampler,  # [DDP] ä¼ å…¥ sampler
        pin_memory=True,
        num_workers=num_workers,
        prefetch_factor=2
    )

    args_override = {
        'kl_weight': KL_WEIGHT,
        'chunk_size': CHUNK_SIZE,
        'hidden_dim': 512,
        'dim_feedforward': 3200,
        'nheads': 8,
        'enc_layers': 4,
        'dec_layers': 1,
        'n_decoder_layers': 1,
        'camera_names': CAMERA_NAMES,
        'state_dim': STATE_DIM,
        'action_dim': ACTION_DIM,
        'lr_backbone': 1e-5,
        'backbone': 'resnet18',
        'masks': False,
        'dilation': False,
        'dropout': 0.1,
        'pre_norm': False,
        'num_queries': CHUNK_SIZE,
    }

    # ä»…ä¸»è¿›ç¨‹æ‰“å°é…ç½®
    if is_main_process():
        config_log = {
            "Experiment Info": {
                "Run Name": RUN_NAME,
                "Mode": mode_str,
                "Device": str(device),
                "Data Dir": DATA_DIR,
                "Resume Path": args.resume if args.resume else "None"
            },
            "Training Hyperparams": {
                "Num Epochs": NUM_EPOCHS,
                "Batch Size (Per GPU)": BATCH_SIZE,
                "Global Batch Size": BATCH_SIZE * world_size,
                "Learning Rate": LR,
                "Chunk Size": CHUNK_SIZE,
                "Camera Names": CAMERA_NAMES
            },
            "Model Architecture": args_override
        }
        logger.info("-" * 60)
        logger.info("ğŸ”§ HYPERPARAMETERS CONFIGURATION:")
        logger.info("\n" + json.dumps(config_log, indent=4, default=str))
        logger.info("-" * 60)

    # æ¨¡å‹åˆå§‹åŒ–
    policy = ACTPolicy(args_override)
    policy.to(device)  # å…ˆç§»è‡³ GPU

    # [DDP] 3. SyncBatchNorm (æ¨è) å’Œ DDP å°è£…
    # å¦‚æœæ¨¡å‹ä¸­æœ‰ BatchNorm å±‚ï¼Œè¿™æ­¥èƒ½åŒæ­¥å‡å€¼æ–¹å·®ï¼Œæå‡å¤šå¡è®­ç»ƒæ•ˆæœ
    policy = torch.nn.SyncBatchNorm.convert_sync_batchnorm(policy)

    # find_unused_parameters=False é€šå¸¸èƒ½æå‡é€Ÿåº¦ï¼Œé™¤éæ¨¡å‹æœ‰äº›å±‚åœ¨å‰å‘ä¼ æ’­ä¸­æœªè¢«ä½¿ç”¨
    policy = DDP(policy, device_ids=[local_rank], output_device=local_rank, find_unused_parameters=True)

    # è·å– optimizer (æ³¨æ„ï¼šDDP åŒ…è£…åï¼Œconfigure_optimizers å¯èƒ½ä¼šå¤±æ•ˆï¼Œå› ä¸ºé‚£æ˜¯åŸæ¨¡å‹çš„æ–¹æ³•)
    # policy ç°åœ¨æ˜¯ DDP å¯¹è±¡ï¼Œpolicy.module æ‰æ˜¯åŸæ¥çš„ ACTPolicy
    optimizer = policy.module.configure_optimizers()

    if args.resume:
        if os.path.isfile(args.resume):
            if is_main_process(): logger.info(f"ğŸ”„ Resuming training from checkpoint: {args.resume}")
            # map_location å¿…é¡»æŒ‡å®š
            checkpoint = torch.load(args.resume, map_location=device)
            policy.module.load_state_dict(checkpoint)  # åŠ è½½åˆ° module
            if is_main_process(): logger.info(f"âœ… Loaded weights successfully.")
        else:
            if is_main_process(): logger.error(f"âŒ Checkpoint file not found: {args.resume}")
            # éä¸»è¿›ç¨‹ä¹Ÿè¦é€€å‡º
            dist.destroy_process_group()
            return

    best_loss = float('inf')
    train_losses = []
    total_start_time = time.time()

    for epoch in range(args.start_epoch, NUM_EPOCHS):
        # [DDP] 4. è®¾ç½® Sampler çš„ epochï¼Œä¿è¯æ¯ä¸ª epoch æ•°æ®ä¹±åºä¸åŒ
        train_sampler.set_epoch(epoch)

        epoch_start = time.time()
        policy.train()
        epoch_loss = 0
        optimizer.zero_grad()

        for batch_idx, data in enumerate(train_loader):
            image_tensor, qpos, action, is_pad = data

            image = image_tensor.to(device, non_blocking=True)
            qpos = qpos.to(device, non_blocking=True)
            action = action.to(device, non_blocking=True)
            is_pad = is_pad.to(device, non_blocking=True)

            # è°ƒç”¨ DDP æ¨¡å‹
            loss_dict = policy(qpos, image, action, is_pad)
            loss = loss_dict['loss']

            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            epoch_loss += loss.item()

        # è®¡ç®—å½“å‰ GPU çš„å¹³å‡ Loss
        avg_loss = epoch_loss / len(train_loader)

        # [DDP] èšåˆæ‰€æœ‰ GPU çš„ Loss ä»¥ä¾¿è®°å½•å’Œä¿å­˜ Best Model
        avg_loss_tensor = torch.tensor(avg_loss, device=device)
        dist.all_reduce(avg_loss_tensor, op=dist.ReduceOp.AVG)
        global_avg_loss = avg_loss_tensor.item()

        # ä»…ä¸»è¿›ç¨‹è´Ÿè´£è®°å½•å’Œä¿å­˜
        if is_main_process():
            train_losses.append(global_avg_loss)
            epoch_dur = time.time() - epoch_start
            eta = str(timedelta(seconds=int((NUM_EPOCHS - epoch - 1) * (time.time() - total_start_time) / (epoch + 1))))

            logger.info(f"Epoch {epoch:04d} | Global Loss: {global_avg_loss:.5f} | Time: {epoch_dur:.1f}s | ETA: {eta}")

            if (epoch + 1) % 50 == 0:
                save_path = os.path.join(CKPT_DIR, f"policy_epoch_{epoch}.ckpt")
                # ä¿å­˜ policy.module.state_dict()ï¼Œå»æ‰ DDP çš„ module å‰ç¼€
                torch.save(policy.module.state_dict(), save_path)
                save_train_loss_plot(RUN_DIR, train_losses, epoch)

            if global_avg_loss < best_loss:
                best_loss = global_avg_loss
                torch.save(policy.module.state_dict(), os.path.join(CKPT_DIR, "policy_best.ckpt"))
                logger.info(f"â­ Best Updated: {best_loss:.5f}")

    if is_main_process():
        logger.info("Training Done!")

    # é”€æ¯è¿›ç¨‹ç»„
    dist.destroy_process_group()


if __name__ == '__main__':
    """
    torchrun --nproc_per_node=4 train_act_ddp.py --video
    """
    main()
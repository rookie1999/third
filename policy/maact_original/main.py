import torch

from policy.maact.common.configs.configuration_act import SpeedACTConfig
from policy.maact.common.model.speed_act_modulate_full_model import SpeedACT


def test_standalone_model():
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ–é…ç½®...")

    # ==========================================
    # 1. é…ç½® Config
    # ==========================================
    config = SpeedACTConfig(
        dim_model=512,
        n_heads=8,
        dim_feedforward=3200,
        n_encoder_layers=2,  # æµ‹è¯•ç”¨ï¼Œå±‚æ•°è®¾å°‘ç‚¹
        n_decoder_layers=2,
        chunk_size=50,
        n_obs_steps=2,  # MA-ACT å¿…é¡» >= 2
        dropout=0.1,

        # è¡¥å…¨ä¹‹å‰æŠ¥é”™ç¼ºå°‘çš„å±æ€§
        feedforward_activation="relu",
        pre_norm=False,

        # SpeedACT ç‰¹æœ‰
        main_camera="camera_front",
        use_optical_flow=True,
        optical_flow_map_height=256,
        optical_flow_map_width=320,
        cropped_flow_h=64,
        cropped_flow_w=64,
        num_speed_categories=3,

        # å¦‚æœä¸éœ€è¦åŠ è½½å®é™…æƒé‡ï¼Œè®¾ä¸º None
        object_detection_ckpt_path=None,
        pretrained_backbone_weights=None
    )

    # ==========================================
    # 2. [å…³é”®ä¿®å¤] æ³¨å…¥ Tensor è€Œä¸æ˜¯ torch.Size
    # ==========================================
    # æ¨¡å‹ä»£ç ä¸­ä½¿ç”¨äº† config.xxx.shape[0]ï¼Œæ‰€ä»¥è¿™é‡Œå¿…é¡»ä¼ å…¥ä¸€ä¸ª Tensor
    # è¿™é‡Œçš„ Tensor å†…å®¹ä¸é‡è¦ï¼Œé‡è¦çš„æ˜¯å®ƒçš„ shape

    # æœºå™¨äººçŠ¶æ€ç»´åº¦ (14,)
    config.robot_state_feature = torch.empty(14)

    # åŠ¨ä½œç»´åº¦ (14,)
    config.action_feature = torch.empty(14)

    # ç¯å¢ƒçŠ¶æ€ (å¯é€‰ï¼Œè¿™é‡Œè®¾ä¸º None)
    config.env_state_feature = None

    # è§†è§‰ç‰¹å¾ï¼šåŒæ ·éœ€è¦ä¼ å…¥æ‹¥æœ‰ .shape å±æ€§çš„ Tensor
    config.image_features = {
        "camera_front": torch.empty(3, 480, 640),
        "camera_wrist": torch.empty(3, 480, 640)
    }

    # ==========================================
    # 3. å®ä¾‹åŒ–æ¨¡å‹
    # ==========================================
    print("ğŸ—ï¸ æ­£åœ¨å®ä¾‹åŒ– SpeedACT æ¨¡å‹...")
    try:
        model = SpeedACT(config)
        print("âœ… æ¨¡å‹å®ä¾‹åŒ–æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹å®ä¾‹åŒ–å¤±è´¥: {e}")
        # æ‰“å°è¯¦ç»†é”™è¯¯æ ˆä»¥ä¾¿è°ƒè¯•
        import traceback
        traceback.print_exc()
        return

    # ==========================================
    # 4. æ„é€ è™šæ‹Ÿè¾“å…¥æ•°æ® (Dummy Batch)
    # ==========================================
    print("ğŸ“¦ æ„é€ æµ‹è¯•æ•°æ®...")
    batch_size = 2

    # SpeedACT éœ€è¦æ—¶åºæ•°æ®: (Batch, Time, ...)
    # Time ç»´åº¦å¿…é¡»ç­‰äº config.n_obs_steps (è¿™é‡Œæ˜¯ 2)

    dummy_batch = {
        # æœºå™¨äººçŠ¶æ€: (B, T, D)
        "observation.state": torch.randn(batch_size, config.n_obs_steps, 14),

        # åŠ¨ä½œç›®æ ‡: (B, Chunk_Size, D)
        "action": torch.randn(batch_size, config.chunk_size, 14),

        # Mask: å…¨ä¸º False è¡¨ç¤ºæ²¡æœ‰ Padding
        "action_is_pad": torch.zeros(batch_size, config.chunk_size, dtype=torch.bool),

        # å›¾åƒæ•°æ®: List å¯¹åº” config.image_features çš„ keys é¡ºåº
        # å½¢çŠ¶: (B, T, C, H, W)
        "observation.images": [
            torch.randn(batch_size, config.n_obs_steps, 3, 480, 640),  # camera_front
            torch.randn(batch_size, config.n_obs_steps, 3, 480, 640)  # camera_wrist
        ]
    }

    # æ¨¡æ‹Ÿ LeRobot æ•°æ®å¤„ç†ï¼Œæ˜¾å¼æ³¨å…¥ä¸»ç›¸æœºæ•°æ®
    # å› ä¸ºæ¨¡å‹å†…éƒ¨ä¼šç”¨ batch[config.main_camera] æ¥è·å–å›¾åƒè®¡ç®—å…‰æµ
    dummy_batch["camera_front"] = dummy_batch["observation.images"][0]

    # ==========================================
    # 5. å‰å‘ä¼ æ’­æµ‹è¯•
    # ==========================================
    print("â–¶ï¸ å¼€å§‹å‰å‘ä¼ æ’­...")
    model.train()  # è®­ç»ƒæ¨¡å¼

    # å¦‚æœæ²¡æœ‰å®‰è£…å…‰æµåº“æˆ–è€…æ²¡æœ‰ GPUï¼Œè¿™é‡Œå¯èƒ½ä¼šæŠ¥é”™
    # æˆ‘ä»¬å¯ä»¥å°è¯• Mock æ‰å…‰æµéƒ¨åˆ†ï¼Œæˆ–è€…ç›´æ¥è¿è¡Œçœ‹è¿æ°”
    try:
        # ç®€å•çš„ Mock å…‰æµç¼–ç å™¨ (å¦‚æœé‡åˆ° correlation æŠ¥é”™ï¼Œè¯·å–æ¶ˆä¸‹é¢æ³¨é‡Š)
        # from unittest.mock import MagicMock
        # model.optical_flow_encoder = MagicMock()
        # model.optical_flow_encoder.return_value = torch.randn(batch_size, 64*64, 512)
        # model.optical_flow_encoder.num_output_tokens = 64*64

        # æ³¨æ„ï¼šå¦‚æœ perform_yolo_detection æ²¡æœ‰æ­£ç¡® Mock ä¸” ckpt_path ä¸º Noneï¼Œ
        # ä»£ç å†…éƒ¨åº”è¯¥ä¼šå¤„ç†è¿”å› Noneï¼Œä¸ä¼šæŠ¥é”™ã€‚

        actions, (mu, log_sigma) = model(dummy_batch)

        print("-" * 30)
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼æµ‹è¯•é€šè¿‡ã€‚")
        print(f"   è¾“å‡º Actions å½¢çŠ¶: {actions.shape} (é¢„æœŸ: [{batch_size}, {config.chunk_size}, 14])")

        if mu is not None:
            print(f"   VAE Latent å½¢çŠ¶: {mu.shape}")
        print("-" * 30)

    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_standalone_model()